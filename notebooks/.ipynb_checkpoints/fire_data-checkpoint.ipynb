{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing fire risk by location in NYC\n",
    "\n",
    "## Background\n",
    "Using data provided by NYC OpenData, this notebook walks through the steps of analyzing fire risk in New York City."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "# Interactive maps\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and describe data\n",
    "\n",
    "Note: Data was filtered on the NYC OpenData site to only include incident classification groups that were fire-related (Structural and NonStructural Fires) prior to export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Connection to azure database \n",
    "# import pandas as pd, pyodbc\n",
    "# server = 'finalprojectdata.database.windows.net'\n",
    "# database = 'v2-project-data'\n",
    "# username = 'finalproject1_pmprybylski'\n",
    "# password = 'firedispatch1!'\n",
    "# driver= '{ODBC Driver 17 for SQL Server}'\n",
    "# # con_string = 'DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password\n",
    "# # con_string = 'DRIVER={SQL Server};SERVER='+ <server> +';DATABASE=' + <database>\n",
    "# # cnxn = pyodbc.connect(con_string)\n",
    "# cnxn = pyodbc.connect(\n",
    "#     'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "#     'SERVER=finalprojectdata.database.windows.net;'\n",
    "#     'PORT=1433;'\n",
    "#     'DATABASE=v2-project-data;'\n",
    "#     'UID=finalproject1_pmprybylski;'\n",
    "#     'PWD=firedispatch1!;'\n",
    "# )\n",
    "# query = \"\"\"\n",
    "# SELECT TOP 3 * FROM cleaned_fire_dispatch_data\n",
    "# \"\"\"\n",
    "# result_port_map = pd.read_sql(query, cnxn)\n",
    "# result_port_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into Python\n",
    "\n",
    "# Fire Incident Dispatch\n",
    "alarms_df = pd.read_csv('../data/raw/In-Service_Alarm_Box_Locations.csv')\n",
    "dispatch_df = pd.read_csv('../data/raw/Fire_Incident_Dispatch_Data.csv')\n",
    "\n",
    "# NYPD Complaints\n",
    "nypd_df = pd.read_csv('../data/raw/NYPD_Complaint_18-21.csv')\n",
    "\n",
    "# Dept of Buildings/Environ Control Board Violations\n",
    "DOB18_df = pd.read_csv('../data/raw/DOB_ECB_Violations_18.csv')\n",
    "DOB19_df = pd.read_csv('../data/raw/DOB_ECB_Violations_19.csv')\n",
    "DOB20_df = pd.read_csv('../data/raw/DOB_ECB_Violations_20.csv')\n",
    "DOB21_df = pd.read_csv('../data/raw/DOB_ECB_Violations_21.csv')\n",
    "\n",
    "# Housing Maintenance Code Violations\n",
    "codev_df = pd.read_csv('../data/raw/Housing_Maintenance_Code_Violations_18-21.csv')\n",
    "\n",
    "# Orders to repair/vacate\n",
    "vacate_df = pd.read_csv('../data/raw/Order_to_Repair_Vacate_18-21.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fire Incident Dispatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Join Fire Dispatch files\n",
    "fires_df = pd.merge(left=alarms_df, right=dispatch_df, left_on='LOCATION', right_on='ALARM_BOX_LOCATION')\n",
    "fires_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "fires_df = fires_df[['STARFIRE_INCIDENT_ID',\n",
    "               'INCIDENT_DATETIME',\n",
    "               'ALARM_BOX_BOROUGH',\n",
    "               'BOROBOX',\n",
    "               'ALARM_BOX_LOCATION',\n",
    "               'LATITUDE',\n",
    "               'LONGITUDE',\n",
    "               'INCIDENT_BOROUGH',\n",
    "               'ZIPCODE',\n",
    "               'INCIDENT_CLASSIFICATION',\n",
    "               'INCIDENT_CLASSIFICATION_GROUP',\n",
    "               'DISPATCH_RESPONSE_SECONDS_QY',\n",
    "               'INCIDENT_RESPONSE_SECONDS_QY',\n",
    "               'INCIDENT_TRAVEL_TM_SECONDS_QY',\n",
    "               'ENGINES_ASSIGNED_QUANTITY',\n",
    "               'LADDERS_ASSIGNED_QUANTITY',\n",
    "               'OTHER_UNITS_ASSIGNED_QUANTITY',]]\n",
    "fires_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data to csv for visualization use\n",
    "fires_df.to_csv('../data/processed/cleaned_fire_dispatch_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert INCIDENT_DATETIME column to datetime\n",
    "fires_df['INCIDENT_DATETIME'] = fires_df['INCIDENT_DATETIME'].apply(lambda x: dt.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))\n",
    "fires_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add a column that splits off the year\n",
    "fires_df['YEAR'] = fires_df['INCIDENT_DATETIME'].dt.year\n",
    "\n",
    "# Move that column to the beginning of the frame\n",
    "year = fires_df['YEAR']\n",
    "fires_df.drop(labels=['YEAR'], axis=1, inplace=True)\n",
    "fires_df.insert(0,'YEAR', year)\n",
    "fires_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training(18-19) and cross-validation(20-21) dataframes\n",
    "fires1 = fires_df.loc[(fires_df.YEAR == 2018)|(fires_df.YEAR == 2019)]\n",
    "fires1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires2 = fires_df.loc[(fires_df.YEAR == 2020)|(fires_df.YEAR == 2021)]\n",
    "fires2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYPD Complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nypd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename columns for easier useage\n",
    "nypd_df.rename(columns={\n",
    "    'CMPLNT_FR_DT':'COMPLAINT_DATE',\n",
    "    'BORO_NM':'BOROUGH',\n",
    "    'CMPLNT_NUM':'NUMBER_OF_COMPLAINTS'\n",
    "}, inplace=True)\n",
    "nypd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data to csv for visualization use\n",
    "nypd_df.to_csv('../data/processed/cleaned_nypd_complaint_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nypd_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert COMPLAINT_DATE column to datetime\n",
    "nypd_df['COMPLAINT_DATE'] = fires_df['COMPLAINT_DATE'].apply(lambda x: dt.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))\n",
    "nypd_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add a column that splits off the year\n",
    "nypd_df['YEAR'] = fires_df['COMPLAINT_DATE'].dt.year\n",
    "\n",
    "# Move that column to the beginning of the frame\n",
    "year = nypd_df['YEAR']\n",
    "nypd_df.drop(labels=['YEAR'], axis=1, inplace=True)\n",
    "nypd_df.insert(0,'YEAR', year)\n",
    "nypd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training(18-19) and cross-validation(20-21) dataframes\n",
    "nypd1 = fires_df.loc[(nypd_df.YEAR == 2018)|(nypd_df.YEAR == 2019)]\n",
    "nypd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nypd2 = nypd_df.loc[(nypd_df.YEAR == 2020) | (nypd_df.YEAR == 2021)]\n",
    "nypd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and cross-validation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dept of Buildings/Environmental Control Board Violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOB18_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOB19_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOB20_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOB21_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns to designate years for each df\n",
    "DOB18_df.insert(0, 'YEAR', '2018')\n",
    "DOB19_df.insert(0, 'YEAR', '2019')\n",
    "DOB20_df.insert(0, 'YEAR', '2020')\n",
    "DOB21_df.insert(0, 'YEAR', '2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOB21_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Borough Number with names based on file schema \n",
    "# 1 = Manhattan\n",
    "# 2 = Bronx\n",
    "# 3 = Brooklyn\n",
    "# 4 = Queens\n",
    "# 5 = Staten Island\n",
    "\n",
    "def f(x):\n",
    "    if x['BORO'] == 1: return 'MANHATTAN'\n",
    "    elif x['BORO'] == 2: return 'BRONX'\n",
    "    elif x['BORO'] == 3: return 'BROOKLYN'\n",
    "    elif x['BORO'] == 4: return 'QUEENS'\n",
    "    elif x['BORO'] == 5: return 'STATEN ISLAND'\n",
    "    else: return ''\n",
    "\n",
    "DOB18_df['BOROUGH'] = DOB18_df.apply(f, axis=1)\n",
    "DOB19_df['BOROUGH'] = DOB19_df.apply(f, axis=1) \n",
    "DOB20_df['BOROUGH'] = DOB20_df.apply(f, axis=1)\n",
    "DOB21_df['BOROUGH'] = DOB21_df.apply(f, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOB18_df.head()\n",
    "# DOB19_df.head()\n",
    "# DOB20_df.head()\n",
    "DOB21_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 2018 and 2019 dataframes for training\n",
    "dobv_df = DOB18_df.append(DOB19_df)\n",
    "dobv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 2020 and 2021 dataframes for cross-validation of predictive algorithm\n",
    "dobv2_df = DOB20_df.append(DOB21_df)\n",
    "dobv2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for easier usage\n",
    "dobv_df.rename(columns={\n",
    "    'YEAR': 'YEAR_OF_COMPLAINT',\n",
    "    'DOB_VIOLATION_NUMBER': 'NUMBER_OF_VIOLATIONS'\n",
    "    }, inplace=True)\n",
    "dobv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobv2_df.rename(columns={\n",
    "    'YEAR': 'YEAR_OF_COMPLAINT',\n",
    "    'DOB_VIOLATION_NUMBER': 'NUMBER_OF_VIOLATIONS'\n",
    "    }, inplace=True)\n",
    "dobv2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "dobv_df = dobv_df[['YEAR_OF_COMPLAINT',\n",
    "                   'BOROUGH',\n",
    "                   'VIOLATION_TYPE',\n",
    "                   'NUMBER_OF_VIOLATIONS'\n",
    "]]\n",
    "dobv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobv2_df = dobv2_df[['YEAR_OF_COMPLAINT',\n",
    "                   'BOROUGH',\n",
    "                   'VIOLATION_TYPE',\n",
    "                   'NUMBER_OF_VIOLATIONS'\n",
    "]]\n",
    "dobv2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing Maintenance Code Violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up date column\n",
    "\n",
    "# Convert INCIDENT_DATETIME column to datetime\n",
    "# codev_df['NOVIssuedDate'] = codev_df['NOVIssuedDate'].apply(lambda x: dt.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))\n",
    "codev_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orders to Repair/Vacate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping alarm boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
